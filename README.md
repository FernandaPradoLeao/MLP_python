# Multilayer perceptron 
 Criação de MLP de classificação em Python
 Grupo de Ciências de Dados da matéria de Otimização aplicada.
 
[![NPM](https://img.shields.io/npm/l/react)](https://github.com/FernandaPradoLeao/MLP_python/blob/main/LICENSE)

# Sobre o projeto
Desenvolvemos uma Rede Neural Perceptron Multicamdas para um dataset da doença diabete e para treinar o modelo utilizamos o Backpropagation. Descrevemos a parte teórica da rede neural MLP e construímos o modelo com base em nosso aprendizado em sala para a realização do projeto.  
A aplicação consiste no EDA do dataset e desenvolvimento do modelo e o treinamento da rede neural.

##### links auxiliares
###### https://medium.com/ensina-ai/rede-neural-perceptron-multicamadas-f9de8471f1a9
###### https://www.youtube.com/watch?v=XYf8EczPysM

## Redes Neurais Multilayer Perceptrons 
O Perceptron é uma rede neural elementar, proposta por Frank Rosenblatt (1959), capaz de realizar tarefas de classificação. Rede neural com uma ou mais camadas ocultas com um número indeterminado de neurônios. A camada oculta possui esse nome porque não é possível prever a saída desejada nas camadas intermediárias. Para treinar a rede MLP, o algoritmo comumente utilizado é o de retropropagação (Backpropagation).

Diferentemente do Perceptron e Adaline, onde existe apenas um único neurônio de saída {y}, o MLP pode relacionar o conhecimento a vários neurônios de saída.

O algoritmo de aprendizagem do MLP é chamado backpropagation é composto de 4 passos:

1º Passo: Inicialização\
2º Passo: Ativação\
3º Passo: Treinar os Pesos\
4º Passo: Iteração

![MLP](https://github.com/FernandaPradoLeao/MLP_python/blob/main/1_piYTTh83qsQJVUMOZKmN5w.png)


# Alunos
Maria Fernanda Prado\
Ana Luiza Ramos\
Ana Luiza Moraes\
Beatriz Vencio\
Artur de Souza

